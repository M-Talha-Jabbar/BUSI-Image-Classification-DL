{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvOwkHVaFF03",
        "outputId": "f693b4d0-98ed-4a01-befe-c41f3ea433b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount google drive on your runtime using and authorization code.\n",
        "# more details here: https://colab.research.google.com/notebooks/io.ipynb\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7bzJcfNgWP2"
      },
      "source": [
        "#Importing libraries and setting random set so we all get same results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtwPTRKaFTMK",
        "outputId": "33c33288-d046-4b12-c324-e63322951df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pickle\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from imutils import paths\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# check GPU is available\n",
        "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# set random seed to be used all over\n",
        "SEED = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "#os.environ['TF_DETERMINISTIC_OPS'] = '1' #deterministic behavior in TensorFlow operations.\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "tf.compat.v1.set_random_seed(SEED)\n",
        "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1,log_device_placement =True)\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.compat.v1.Session(graph = tf.compat.v1.get_default_graph(), config = config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1W9PxYZgcrU"
      },
      "source": [
        "#Getting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqiIetRtF8AY"
      },
      "outputs": [],
      "source": [
        "# Path to the directory containing the your project info (Change to your location)\n",
        "PROJECT_ROOT_DIR = '/content/drive/MyDrive/CS5331_CS4331_Fa24/img/'\n",
        "\n",
        "# Path to the directory containing the dataset\n",
        "# DOWNLOAD BUSI dataset here: https://scholar.cu.edu.eg/?q=afahmy/pages/dataset\n",
        "DATA_DIR = 'Dataset_BUSI_with_GT/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mjYED0feHUYZ"
      },
      "outputs": [],
      "source": [
        "# Funciton for loading the dataset\n",
        "# reference: https://www.pyimagesearch.com/2018/09/10/keras-tutorial-how-to-get-started-with-keras-deep-learning-and-python/\n",
        "\n",
        "def load_image():\n",
        "  # initialize the data and labels for each class\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  data_aside = []\n",
        "  labels_aside = []\n",
        "\n",
        "  benign_data = []\n",
        "  benign_labels = []\n",
        "\n",
        "  malignant_data = []\n",
        "  malignant_labels = []\n",
        "\n",
        "  normal_data = []\n",
        "  normal_labels = []\n",
        "\n",
        "  # load benign image\n",
        "  for i in range(1,438):\n",
        "    image = cv2.imread(PROJECT_ROOT_DIR + DATA_DIR + 'benign/' + 'benign (' + str(i) + ').png')\n",
        "    # resize image to 224 * 224 * 3\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    benign_data.append(image)\n",
        "    # extract the class label from the image folder\n",
        "    benign_labels.append('benign')\n",
        "\n",
        "  for i in range(0,437):\n",
        "      data.append(benign_data[i])\n",
        "      labels.append(benign_labels[i])\n",
        "\n",
        "  # load malignant image\n",
        "  for i in range(1,211):\n",
        "    image = cv2.imread(PROJECT_ROOT_DIR + DATA_DIR + 'malignant/' + 'malignant (' + str(i) + ').png')\n",
        "    # resize image to 224 * 224 * 3\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    malignant_data.append(image)\n",
        "    # extract the class label from the image folder\n",
        "    malignant_labels.append('malignant')\n",
        "\n",
        "  for i in range(0,210):\n",
        "      data.append(malignant_data[i])\n",
        "      labels.append(malignant_labels[i])\n",
        "\n",
        "  # load normal image\n",
        "  for i in range(1,134):\n",
        "    image = cv2.imread(PROJECT_ROOT_DIR + DATA_DIR + 'normal/' + 'normal (' + str(i) + ').png')\n",
        "    # resize image to 224 * 224 * 3\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    normal_data.append(image)\n",
        "    # extract the class label from the image folder\n",
        "    normal_labels.append('normal')\n",
        "\n",
        "  for i in range(0,133):\n",
        "      data.append(normal_data[i])\n",
        "      labels.append(normal_labels[i])\n",
        "\n",
        "  return data, labels\n",
        "# Function for image preprocessing\n",
        "def preprocess(data,labels):\n",
        "  # Save training and test image to numpy, Scale image features to be in [0, 1]\n",
        "  data = np.array(data, dtype = np.float32) / 255.0\n",
        "  # Save labels to numpy encode label to integer catergory 0 = 'benign', 1 = 'malignant', 2 = 'normal'\n",
        "  labels = np.array(labels)\n",
        "  new_label_encoder = preprocessing.LabelEncoder()\n",
        "  new_label_encoder.fit(labels)\n",
        "  targets = new_label_encoder.transform(labels)\n",
        "\n",
        "  return data, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hF5jQ-6HaWM"
      },
      "outputs": [],
      "source": [
        "# Load the BUSI images and labels\n",
        "# This will take time (my time was around 12 min)\n",
        "data, labels = load_image()\n",
        "data, labels = preprocess(data,labels)\n",
        "\n",
        "# split data into 80% train and 20% test, shuffle the data with\n",
        "(imgs_train, imgs_test, labels_train, labels_test) = train_test_split(data, labels, test_size = 0.2, random_state=SEED, shuffle = True)\n",
        "# split data into 60% train data and 20% validation data\n",
        "(imgs_train, imgs_val, labels_train, labels_val) = train_test_split(imgs_train, labels_train, test_size = 0.2, random_state=SEED, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PVU-E5AHm03"
      },
      "outputs": [],
      "source": [
        "# Display the shapes of train, validation, and test datasets\n",
        "print('Images train shape: {} - Labels train shape: {}'.format(imgs_train.shape, labels_train.shape))\n",
        "print('Images validation shape: {} - Labels validation shape: {}'.format(imgs_val.shape, labels_val.shape))\n",
        "print('Images test shape: {} - Labels test shape: {}'.format(imgs_test.shape, labels_test.shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v2qZ3bGgr2v"
      },
      "source": [
        "# Set constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JbwRwqIIFDh"
      },
      "outputs": [],
      "source": [
        "NUM_LABELS = 3                             # Number of labels\n",
        "BATCH_SIZE = 16                             # Size of batch\n",
        "HEIGHT = 224                                 # Height of input image\n",
        "WIDTH = 224                                  # Width of input image\n",
        "N_CHANNEL = 3                               # Number of channels\n",
        "OUTPUT_DIM = 3                             # Number of output dimension\n",
        "\n",
        "# Set training hyperparameters\n",
        "NUM_EPOCH = 100                             # Number of epoch to train\n",
        "LR = 0.0001                                 # Learning rate\n",
        "\n",
        "INPUT_SHAPE = (HEIGHT, WIDTH, N_CHANNEL)  # Input shape of model\n",
        "IMG_SHAPE = (HEIGHT, WIDTH, N_CHANNEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srHYqdWfgwzV"
      },
      "source": [
        "# Converting the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IHv1efbIfUr"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "labels_train = keras.utils.to_categorical(labels_train, NUM_LABELS)\n",
        "labels_test = keras.utils.to_categorical(labels_test, NUM_LABELS)\n",
        "labels_val = keras.utils.to_categorical(labels_val, NUM_LABELS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZVrrwoBq4R4"
      },
      "source": [
        "# Task1: Simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQrkiTB_q60v"
      },
      "outputs": [],
      "source": [
        "# For your first task, you will train a Convolutional Natural Network (CCN) model with the parameters in Table 1 and provide us with the results.\n",
        "# You can use already developed models for Kears, TensorFlow, and PyTorch. You don’t need to implement the models’ layers yourself.\n",
        "# For this task, you don’t need to do hyper-parameter tuning, apply data augmentation, or fine-tune the layers of the models unless you wish to.\n",
        "\n",
        "# Here few steps that you could follow\n",
        "\n",
        "\n",
        "# Import what ever libraries you need\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Build your network\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create and compile the pretrained model\n",
        "\n",
        "\n",
        "# Train/Fit the model\n",
        "\n",
        "\n",
        "# evaluate Your model\n",
        "\n",
        "\n",
        "#  Plot accuracy\n",
        "\n",
        "\n",
        "#  Plot Loss\n",
        "\n",
        "\n",
        "\n",
        "# save model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHCpI7O6rddp"
      },
      "source": [
        "# Task 2: Enhance the performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5C22WC6I8r3"
      },
      "outputs": [],
      "source": [
        "# CS5331/CS4331 You should Impliment this part\n",
        "# Task 2 Impliment an enhanced DL performance\n",
        "# You must train a DL model to achieve 85% or above testing accuracy.\n",
        "# You are restricted to using the parameters provided in Table 3.\n",
        "# You should start with pre-trained weights (e.g., on ImageNet, which is already available on Keras). It should result in a better performance.\n",
        "# Any other hyper-parameter tuning, DL model use, data augmentation, or fine-tuning of the layers of the models is fine as long as you reach the desired accuracy.\n",
        "# You will need to try at least a couple of parameters to reach the desired accuracy.\n",
        "\n",
        "# Here few steps that you could follow\n",
        "\n",
        "# Import what ever libraries you need\n",
        "\n",
        "# Load some pretrained model\n",
        "\n",
        "\n",
        "# Decide on model parameters\n",
        "\n",
        "\n",
        "\n",
        "# Train/Fit the model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# evaluate Your model\n",
        "\n",
        "\n",
        "\n",
        "#  Plot accuracy\n",
        "\n",
        "\n",
        "\n",
        "#  Plot Loss\n",
        "\n",
        "\n",
        "# save model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHa7WhIvt0xx"
      },
      "source": [
        "# Taks 3: Avoiding Overfitting\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOdOeKnKL5qV"
      },
      "outputs": [],
      "source": [
        "# CS5331/CS4331 You should Impliment this part\n",
        "\n",
        "# Now, let’s fix the problem with the previous model. Most models in the last task were overfitting (training accuracy got to 100% so quickly, and validation accuracy started to decrease).\n",
        "# Fix that problem without changing the batch size, number of iterations, or learning rate.\n",
        "# Any avoiding overfitting can be used. Just keep the parameters in Table 3 the same.\n",
        "\n",
        "# Here few steps that you could follow\n",
        "\n",
        "\n",
        "# Import what ever libraries you need\n",
        "\n",
        "# Load some pretrained model\n",
        "\n",
        "# Decide on Fine-tuning parameters\n",
        "\n",
        "\n",
        "\n",
        "# Train/Fit the model\n",
        "\n",
        "\n",
        "\n",
        "# evaluate Your model\n",
        "\n",
        "\n",
        "\n",
        "#  Plot accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#  Plot Loss\n",
        "\n",
        "\n",
        "# save model\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
